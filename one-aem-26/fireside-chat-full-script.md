# The AI-Native Organization: A Fireside Chat

> **Format**: ~18-minute fireside chat
> **Speakers**: MOD (Moderator, male) — TL (Thought Leader, female)
> **Source**: One AEM Workshop, February 26, 2025 — 9 sessions, full strategic recap
> **Note**: Script is split into 4 parts for ElevenLabs Text-to-Dialogue API generation.

---

## Part 1: The Wake-Up Call

**MOD:** So — nine sessions, two external keynotes, an SVP roundtable, a Dragon's Den. This wasn't your average offsite. What was the single question that set the tone?

**TL:** Amit opened the SVP roundtable by asking, "Are we moving fast enough?" And what made it land was the framing. He wasn't criticizing the team. He called them poster children for reinvention. So it was a dare, not a complaint. Like — you've earned the right to be restless. Now prove you can stay ahead.

**MOD:** That's a powerful opener. And then you had two external keynotes that came at the same question from very different angles.

**TL:** Exactly. Alex Koren from Anthropic gave the opening keynote, and his thesis was sharp: AI-first does not mean AI-assisted. It means AI as infrastructure. Not a tool you pull out when you're stuck — more like the substrate everything runs on. He laid out a maturity curve. Most teams are at level one. The target is level four. And the distance between those isn't incremental. It's structural. You can't get there by doing more of what you're already doing.

**MOD:** And the Microsoft keynote?

**TL:** Brendan Burns from Azure took a deliberately pragmatic approach. His mantra was almost deceptively simple: use the tools, get everyone to use the tools, repeat step one. He made this great observation — the first time someone tries an AI tool, they usually think "this doesn't work." The second time, they realize "wait, this actually works." That gap between those two reactions? That's the adoption gap. That's where most organizations stall.

**MOD:** So one speaker says rebuild everything, the other says just start using it.

**TL:** And they're both right. Burns also said — rethink everything, talk to everyone, remember that learning is the job, not a distraction from it. When you put the two keynotes together, the synthesis is clear. We're not bolting AI onto old workflows. We're rebuilding how work itself operates. Not AI-assisted. AI-native.

**MOD:** And Amit's reaction to all of this?

**TL:** He brought it back to accountability. He talked about the "sheer freakiness" of the agentic web — the pace of change, the new players showing up. But then he said two words that became the standard for the entire workshop: "Show me." Not as a threat — as a bar. The era of promising transformation is over. Now you have to prove it. Show the customer, show leadership, show the market.

---

## Part 2: The Product Bet and the Market Split

**MOD:** Let's talk about where all this transformation points. What's the product destination?

**TL:** One AEM. And what the workshop did was make the product vision concrete in a way the team hadn't experienced before. The internal keynote — led by Loni Stark, Alexander Saar, Conrad Walton, and Michael Marth — laid out the bridge from FY25 to FY26. The mandate was clear: shared understanding, ownership, accountability, and above all — usage. Usage is the leading indicator. If people aren't using it, nothing else matters.

**MOD:** What are the big bets?

**TL:** Site Optimizer, Live Preview, Product Telemetrics as the measurement backbone, the Experience Hub, Content AI, AI Assistants, and Project 42 — which is Adobe's initiative to build a suite of agentic capabilities. Experience production agents, discovery agents, content optimization, governance, development — all managed through a unified control plane.

**MOD:** That's a lot of surface area. What's the market thesis underneath it?

**TL:** The market is bifurcating. On one side, you have generic AI-driven discovery — users get answers, but no brand relationship. On the other side, owned brand experiences — differentiated, delightful surfaces where the brand controls the relationship. And there was this equation that kept coming up: Experience equals Content plus Code. That's our territory.

**MOD:** Where does Edge Delivery Services fit?

**TL:** EDS is the technical substrate. Speed, simplicity, built-up context. It gives us the performance foundation. But the session went further than just technology. The competition is becoming agent-ready. The data renaissance is real. Governance is becoming a differentiator, not a checkbox. And buy-versus-build dynamics are shifting fast.

**MOD:** Someone used the word "Disneylandification."

**TL:** That was Loni Stark, and it stuck. The brand experience must delight like Disneyland, not read like a brochure. When users enter a brand surface, they expect an experience — actionable, immersive, trust-building. It means finding the trust signals that actually change behavior. Not generic badges. Context-aware proof points that matter to this user at this moment.

**MOD:** And the strategic priorities?

**TL:** Four commitments. Grow the flagship product thirty percent year-over-year — that's the revenue anchor. Own Brand AI Intelligence — the data and insight layer. Power Brand Deployed AI — the infrastructure for brands to deploy AI in their own experiences. And prove Humanity plus AI value — measurably demonstrate that human creativity combined with AI capability produces outcomes neither achieves alone.

**MOD:** Amit added a very specific test for all of this.

**TL:** The lighthouse customer. The goal for the year: a real customer who can say, unprompted, "I embarked on this agentic evolution with Adobe, and this is the value I'm getting." Not a case study written by marketing. A customer who believes it and says it because it's true. That's what "show me" means at the product level.

---

## Part 3: The Engineer of 2026

**MOD:** This is the part that I think rattles people a little. The engineering role itself is changing.

**TL:** This was the conceptual heart of the workshop. Alex Koren's maturity framework gave us a shared vocabulary. Four levels. Level one: you use AI sometimes. Level two: AI is your default starting point for most tasks. Level three: your entire workflow is restructured around AI as infrastructure. Level four: the whole team operates this way with shared tooling and norms. And here's the critical insight — getting individuals to level three is a training problem. Getting the team to level four is a systems problem. They need fundamentally different interventions, and almost everyone is only investing in training.

**MOD:** What does level three actually look like in practice?

**TL:** Boris Cherny from Anthropic gave us the proof point. In December, Boris shipped over three hundred pull requests. One person. And he wasn't working crazy hours. His method: five Claude Code terminals running in parallel on his machine, plus five to ten browser sessions, totaling ten to fifteen concurrent agent sessions. He has a plan-first discipline — iterate with the AI until the plan is solid, then switch to execution. Each agent commits, pushes, and opens a pull request when done. Automated CI, review, and merge workflows handle the rest. One person, team-level throughput, zero extra hours.

**MOD:** Three hundred PRs in a month. That's... a lot.

**TL:** It is. And Titus Winters from the Engineering Culture session framed why this matters. The engineer's job shifts from writing code to three things: plan, execute, verify. Design the plan, orchestrate execution through agents, verify the output. And his key point — coding is probably not the bottleneck anymore. Thinking clearly is. Design, architecture, judgment — those are the skills that matter when agents handle implementation.

**MOD:** People hear that and think — so the job gets easier?

**TL:** No. Harder. Winters was explicit about that. It demands more clarity of thought, better decomposition of problems, sharper judgment about what good looks like. New muscles are required. The transition needs safety, training, and patience.

**MOD:** And the team structure changes too.

**TL:** Fluid teams. Instead of one team of ten people on one initiative, the same headcount fans out into four crews of one to two engineers plus agents, each covering an independent track. Product and design float across crews. Tasks become shorter, more frequent, massively parallel. The unit of work changes shape — from one person on one long sequential task to one person running many short tasks in parallel through agents.

**MOD:** So the payoff is real, but so is the difficulty of getting there.

**TL:** Exactly. Boris proved the payoff. The workshop acknowledged the difficulty. One person with the throughput of a team. A team with the throughput of a division. That's not theoretical anymore. But the path from here to there requires genuine investment in both people and systems.

---

## Part 4: Culture, Innovation, and Monday Morning

**MOD:** You can have the best strategy and the best tools, but if the culture resists it, nothing happens.

**TL:** The workshop didn't leave culture to chance. The Anthropic keynote introduced five culture pillars. AI-First — try AI before asking a colleague. Push Boundaries — every task is an opportunity to find AI leverage. Write and Share — document what you learn, because learning that stays with one person is waste. Fail Fast — the cost of trying has collapsed, so the cost of not trying is falling behind. And Stay Skeptical — the harder you lean on AI, the sharper your judgment needs to be.

**MOD:** Those feel like individual practices though. What about the team level?

**TL:** Exactly the right distinction. They added four team-level pillars. Build for the Team — when you automate something, package it for others, not just yourself. Make It Visible — work and experiments should be visible by default, not by effort. Have Fun Doing It — if the transformation drains people, it's broken regardless of output. And Elevate, Don't Grind — delegate everything you can, spend your time at the highest level of thinking you're capable of.

**MOD:** And then there were two words that kept coming up.

**TL:** "Be Pirates." Explicitly sanctioned at the director-plus level. Break rules, expense tools, experiment freely. The single biggest blocker to transformation is fear of getting in trouble. "Be Pirates" removes it. It's not a slogan. It's a cultural license with organizational backing. When someone breaks a rule and it pays off, celebrate loudly. When it doesn't, celebrate the learning.

**MOD:** Did people actually demonstrate this pirate energy?

**TL:** The Dragon's Den proved it. Six teams pitched ideas they had prototyped — a one-on-one management tool, a page speed budgeter, a roadmap roulette game, a knowledge garden for growing team skills. Every pitch showed people building things because they wanted to, not because they were told to. That's what real permission to experiment looks like.

**MOD:** There were also some wild automation concepts.

**TL:** Three stood out. A zero-touch meeting pipeline — you join a customer call, the meeting ends, and without any action a transcript is generated, fed into a shared context store, and distilled into learnings and next actions. An auto-demo generator — someone works on a proof-of-concept and the system inspects the code, writes a demo script, records a walkthrough, and posts a one-minute video to Slack. And my favorite — the overnight idea factory. Agents generate ideas, implement them overnight using multiple approaches, critique each other's results, and elect winners. The engineer arrives in the morning to ranked, working prototypes.

**MOD:** Sleep becomes productive time. That's a sentence.

**TL:** It is. And there's a deeper identity emerging — the team is becoming an applied research team. Every internal tool is a product insight. Every workflow experiment is R&D. When someone builds a meeting pipeline, they're conducting applied research into the future of work.

**MOD:** So — all of this lands on someone's desk Monday morning. What happens?

**TL:** Five commitments. One: usage as north star — track it weekly, make it the first metric the team sees. Two: lighthouse customer by year-end — a real partnership, a customer who says unprompted that the value is real. Three: AI maturity jump — every individual moves up at least one level by mid-year, team-level-four infrastructure is in place by year-end. Four: Be Pirates, visibly — experimentation sanctioned, celebrated, and shared. Five: prove Humanity plus AI with measurable outcomes, not aspirational statements.

**MOD:** And the answer to Amit's opening question — are we moving fast enough?

**TL:** The answer isn't yes or no. It's — now we know what fast enough looks like. Engineers managing fleets of agents, shipping three hundred PRs without burning out. Fluid teams of one or two people covering what used to require ten. A pipeline from experiment to production. A culture where "Be Pirates" is daily practice, not a poster on the wall. The vision is clear. The framework is set. The permission is granted. Now it's about making it real.

**MOD:** Building the AI-native organization — not a technology upgrade, but a reinvention of product, engineering, and culture.

**TL:** And the organizations that figure it out first make it structurally impossible for the rest to catch up.

**MOD:** Strong note to end on. Thank you.

---

*Based on 9 sessions from the One AEM Workshop, February 26, 2025.*
